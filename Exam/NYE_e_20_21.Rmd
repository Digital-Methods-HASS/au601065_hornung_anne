---
title: "Queen Margrethe II's New Year’s Address 2020+2021 (English)"
author: "Anne Louise Bank Hornung"
date: "created 7/1/2023, updated date: `r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Getting started on the Queen's speeches 2018/2019 (English)

```{r getting started}

# Attaching packages and lexicon
library(tidyverse)
library(here)

# For text mining
library(pdftools)
library(textdata)
library(tidytext)
library(ggwordcloud)

# For later sentiment analysis

# Categorizes into 8 emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust) and positive / negative
get_sentiments(lexicon = "nrc")

# Assigns words with a score that runs between -5 and 5 (-5 most negative sentiment, 5 most positive sentiment)
get_sentiments(lexicon = "afinn")

# Categorizes words into a binary fashion (positive and negative)
get_sentiments(lexicon = "bing")
```

## Get the 2020-2021 translated English NYE speeches from the Queen
```{r get-documents}

NYE_q_e_20_21_path <- here("data","NYE_q_e_20_21.pdf")
NYE_q_e_20_21_text <- pdf_text(NYE_q_e_20_21_path)

```


```{r single page extract}

# Attempt single page extract to make sure the pages in the NYE_q_e_20_21.pdf are the same as when running it here
NYE_q_e_20_21_p3 <- NYE_q_e_20_21_text[3]

NYE_q_e_20_21_p3

# It is indeed the same pages
```

## Wrangling

```{r wrangling}
# Wrangling to split up pages into different lines, unnest into regular columns, and removing leading/trailing white space

NYE_q_e_20_21_df <- data.frame(NYE_q_e_20_21_text) %>% 
  mutate(text_full = str_split(NYE_q_e_20_21_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full))

```


## Get the tokens (individual words) in tidy format
```{r tokenize}

NYE_q_e_20_21_tokens <- NYE_q_e_20_21_df %>% 
  unnest_tokens(word, text_full)

# now there are only words, no punctuations or similar, and each word has its own row

```

# Count words
```{r word count}

# count the words
NYE_q_e_20_21_wc <- NYE_q_e_20_21_tokens %>% 
  count(word) %>% 
  arrange(-n)

NYE_q_e_20_21_wc
# there are too many superfluous words, so we need to do a stopword removal in English

```


```{r stopwords removal}

# Stop words removal
NYE_q_e_20_21_stop <- NYE_q_e_20_21_tokens %>% 
  anti_join(stop_words) %>% 
  select(-NYE_q_e_20_21_text)

```

```{r second word count}

# check word count again
NYE_q_e_20_21_swc <- NYE_q_e_20_21_stop %>% 
  count(word) %>% 
  arrange(-n)
# new word count shows 645 words

```

(by this time it could be relevant to remove numbers also, but since it's a NYE speech, it could contain relevant numbers)

## Word cloud of NYE_q_e_20_21 speech words
```{r word cloud prep}

# Prep to find number of unique words

length(unique(NYE_q_e_20_21_stop$word))

# there are 645 unique words, but these are too many for a word cloud, so I'll find the 100 most frequent words

NYE_q_e_20_21_top100 <- NYE_q_e_20_21_stop %>% 
  count(word) %>% 
  arrange(-n) %>% 
  head(100)
```


```{r word cloud}
# Make a word cloud of the English top100
NYE_q_e_20_21_cloud <- ggplot(data = NYE_q_e_20_21_top100, aes(label = word)) +
  geom_text_wordcloud() +
  theme_minimal() +
  labs(title = "Basic word cloud")

NYE_q_e_20_21_cloud

# customization of word cloud
ggplot(data = NYE_q_e_20_21_top100, aes(label = word, size = n)) +
  geom_text_wordcloud_area(aes(color = n), shape = "pentagon") +
  scale_size_area(max_size = 8) +
  scale_color_gradientn(colors = c("black","blue","red")) +
  theme_minimal() +
  labs(title = "Most frequently occuring words")

```


### Sentiment analysis with afinn, nrc and bing
```{r afinn}

# Bind words in `NYE_q_e_20_21_stop` to `afinn` lexicon:
NYE_q_e_20_21_afinn <- NYE_q_e_20_21_stop %>% 
  inner_join(get_sentiments("afinn"))

# Find counts by sentiment ranking
NYE_q_e_20_21_afinn_hist <- NYE_q_e_20_21_afinn %>% 
  count(value)

# there are most word ranked 1 and 3 on sentiment scale. In 18_19, there were most words ranked 1 and 2
# there are also more words ranked -3 in 20_21 than in 18_19 (only 3 words ranked -3 in 18_19, in 20_21 10 words ranked -3)

# Plot 
ggplot(data = NYE_q_e_20_21_afinn_hist, aes(x = value, y = n)) +
  geom_col() +
  labs(title = "Sentiment ranking")
# There are most word ranked 1 and 3 on the afinn sentiment scale
# Not surprising, since it's a motivational speech

# Go in depth with the words ranking -3 on afinn scale
NYE_q_e_20_21_afinn2 <- NYE_q_e_20_21_afinn %>% 
  filter(value == -3)
# crisis is dominating the -3 field

# Check unique -3-score words
unique(NYE_q_e_20_21_afinn2$word)

# Count & plot them
NYE_q_e_20_21_afinn2_n <- NYE_q_e_20_21_afinn2 %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(factor(word), n))

ggplot(data = NYE_q_e_20_21_afinn2_n, aes(x = word, y = n)) +
  geom_col() +
  coord_flip() +
  labs(title = "Top -3 words")
# None of the occuring -2 words in the plot stick out as being misinterpreted or lost in translation

```

```{r summarize afinn}

# summarize afinn
NYE_q_e_20_21_summary <- NYE_q_e_20_21_afinn %>% 
  summarize(
    mean_score = mean(value),
    median_score = median(value)
)

NYE_q_e_20_21_summary

# summary shows the mean score to be 0,7 and the median to be 1. 
# Mean score is slightly lower in 20_21 than in 18_19 where it was 0,9
# slightly positive speech based on afinn

```


```{r nrc}

# "binning" text by the feelings they're typically associated with
NYE_q_e_20_21_nrc <- NYE_q_e_20_21_stop %>% 
  inner_join(get_sentiments("nrc"))

# check exclusions
NYE_q_e_20_21_exclude <- NYE_q_e_20_21_stop %>% 
  anti_join(get_sentiments("nrc"))

## View(NYE_q_e_20_21_exclude)
# Count to find the most excluded
NYE_q_e_20_21_exclude_n <- NYE_q_e_20_21_exclude %>% 
  count(word, sort = TRUE)

head(NYE_q_e_20_21_exclude_n)

# many words from `NYE_q_e_20_21_exclude_n´ could have been included in sentiment analysis

```

```{r bing}

# counts
NYE_q_e_20_21_nrc_n <- NYE_q_e_20_21_nrc %>% 
  count(sentiment, sort = TRUE)

# way more negative (83 in 20_21, 54 in 18_19)
# way more fear (60 in 20_21, 35 in 18_19)

# Plot them
ggplot(data = NYE_q_e_20_21_nrc_n, aes(x = sentiment, y = n)) +
  geom_col() +
  labs(title = "Sentiment category frequency")

# Compared to the NYE_e_18_19, there is a visible difference in where the words are "binned"
# The positive bin dominates, but the negative bin is almost equal to (or higher than) joy, anticipation and trust
# The sadness bin is also higher in the 2020+2021 speeches than in the 2018+2019 speeches
# The likely explanation in the mention of coronavirus-related words

# Ccount by sentiment and word, and then facet
NYE_q_e_20_21_nrc_n5 <- NYE_q_e_20_21_nrc %>% 
  count(word,sentiment, sort = TRUE) %>% 
  group_by(sentiment) %>% 
  top_n(5) %>% 
  ungroup()

NYE_q_e_20_21_nrc_gg <- ggplot(data = NYE_q_e_20_21_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, ncol = 4, scales = "free") +
  coord_flip() +
  theme_minimal() +
  labs(x = "Word", y = "Count")

NYE_q_e_20_21_nrc_gg

# save it
ggsave(plot = NYE_q_e_20_21_nrc_gg, 
       here("fig_output","NYE_q_e_20_21_nrc_sentiment.png"), 
       height = 8,
       width = 7)
```




